## 为什么使用消息队列

解耦：多个模块互相调用，维护起来很麻烦

异步：非核心功能没有必要立即返回只要能确保完成即可，降低请求的等待时间

削峰：MQ削去高峰期的突发请求。

## 优点和缺点

系统可用性降低：如果MQ发生故障，就无法传递消息，整个系统崩溃

系统复杂性提高：本来只需要调用一次，如果发生消息时出错，发送2条则会出现问题

一致性问题：某一部分业务成功，某一个部分失败，但是客户收到的是成功，不一致

## 各种MQ的对比

| 特性                     | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级                        | W                                                            | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                                              |                                                              | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                                        | 微秒级，这是 RabbitMQ 的一大特点，延迟最低                   | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用                                   | 高                                                           | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                                         | 基本不丢                                                     | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                                        | 基于 erlang 开发，并发能力很强，性能极好，延时很低           | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |
| 优缺点                   | 成熟，但社区不活跃，会丢消息,基于解耦和异步，较少在大规模吞吐的场景中使用 | 性能好，社区活跃，页面交互良好，吞吐量相对低一点，动态扩展很难 | 接口简单易用，大规模吞吐量，分布式扩张好，社区维护好，       | 适用于大数据，功能很小，但是吞吐量很大。                     |

最早用activeMQ,后来用rabbitMQ,

RocketMQ,可以，

大数据场景，kafka

## 如何保证高可用

rabbitMQ 不是分布式，可以搭集群

三种模式，单机模式、普通集群模式、镜像集群模式

1. 单机

2. 普通：只有某一个节点，包含元数据和实际数据，需要连接到真正包含数据的MQ上拿数据

    在rabbitMQ内部 大量的数据传输，基本没有什么高可用

3. 镜像：元数据和实际数据都包含在每一个队列中，可以从任意节点读取

    每一个节点都包含所有queue的全部数据，消费者可以任何一个节点消费

    只有在写消息的时候才会有MQ之间数据传输

    任何一个节点宕机，其他节点上还有queue的完整数据，可以到其他节点上消费数据，

    缺点：不是分布式

管理控制台中添加一个策略。。只要指定创建时设置这个策略就可以实现高可用



## kafka

会在每台机器上启动一个broker进行，每台机器加上机器上的broker进行就可以认为是一个kfaka节点，



## 如何保证消息不被重复消费



幂等性：一个数据重复出现多次，数据应该还是是对的，不能出现错误

出现原因：

> kafka：offset并不会立即提交，而是定时的，那么就会出现问题，我消费了，但是却没有提交，下次重启服务器之后，就会造成数据的重复消费。、

解决方法：

消费时不直接消费，可以放置到一个set集合中，这样就会过滤重复的数据，不会再执行。

如何保证MQ消费是幂等性的，要结合的具体的业务



## 保证消息的可靠性传输，如何处理消息的丢失的问题

基于rabbitMQ支持事务：发送消息之前开启事务，出现异常回滚，可以再次重试发送这条消息，如果没有报错，可以提交事务，

事务机制，是同步的，生产者发送消息会同步阻塞卡主，等待你成功还是失败，会导致吞吐量降下来

生产者防止消息丢：

>  channel.confirm    生产者会接收到rabbitmq返回的接受消息的接口  
>
> 异步，并且不会丢 吞吐量会高

rabbitmq不丢消息：

> 开启rabbitmq的持久化，创建queue的时候就设置其为持久化的，第二个 发送消息的时候deliveryMode设置为2，就是将消息设置装换为持久化，此时会将消息也持久化到磁盘中



消费者丢失：

> 消费者开启了 autoack ，如果消费到了一条消息，还在消费没有处理完，消费者自动autoack，通知rabbitmq消费完了，但是此时宕机，rabbitmq会认为消息已经处理完了
>
> 需要关闭autoack，每次处理完之后，才返回ack给rabbitmq,如果宕机会重新发送。

kafka：

broker宕机丢失消息



## 如何保证消息的顺序性

场景：

1. rabbitmq:一个队列，多个消费者，会乱

    > 解决方法：
    >
    > 一个队列只绑定一个queue，需要保证顺序的数据， 全部都放到一个队列中去。

2. kafka: 消费者处理消息时如果使用多个线程处理数据，那么就会乱

    kafaka可以保证 写入一个partition中的数据一定是有顺序的

    > 生产者在写的时候，可以指定一个key   比如订单号，这样和这个订单有关的数据一定会被分发到一个partition中去，而且这个partition中的数据一定是有顺序的
    >
    > 消费者从partition中取出数据的是，一定是有顺序的。
    >
    > 解决方法：
    >
    > 如果确实需要多个线程，消费者 创建多个内存队列，根据key分发到同一个内存queue中
    >
    > 线程也会按照顺序进行写入。
    >
    > 如果kafka是单线程且处理比较耗时，处理消息一秒钟只能处理几十毫秒，消费者肯定需要多线程，4 8G  32条线程，每秒可以处理上千条消息

## 消息积压几小时

消费者挂了，MQ积压几千条数据，且经过好几个小时

kafka

> 1 快速处理积压的消息
>
> 消费者修复了，需要开始消费消息，现在问题在于如何将几百万数据处理掉
>
> 解决方法：3个消费者，意味着有3个partition，
>
> 新建一个topic  有30个partition，原来的消费者更改为现在的新的topic，30个新的消费者消费30个partition

rabbitmq：设置了过期时间，如果积压了过长时间会自动失效，

只能手动补单   闲时，再查出来重新写入

rabbitmq内存积压满了， 快速消费数据，写入磁盘。



## 消息中间件的架构

1. 一个MQ需要支持扩容，设计一个 分布式集群，参照kafka的设计理念

borker-topic-partition,每个partition放一个机器，如果资源不够了就增加，然后做数据迁移，增加机器就可以存放更多的数据，提高等多的吞吐量

2. MQ需不需要持久化，保证数据不丢

需要顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能很高，这就是kafka的思路

3. 高可用，

参考kafka高可用，每个partition都要有副本，保证消息不能丢失，主机挂了的时候重新选举出一个就可以对外服务

4. 数据0丢失
5. 重复消费

## 总结队列问题

rabbitmq   

kafka

## 分布式搜索引擎 ES

Lucene入门

倒排索引：

全文检索：

Es

1. 分布式架构原理
2. 写入数据的工作原理，查询数据的工作原理
3. 数据量的很大的情况下，如果提高查询的性能
4. 生产集群的部署架构，每个索引的数量大概有多少，每个索引有多少分片

## es如何实现分布式

多台机器上的多个ES组成了一个ES集群

ES存储数据的基本类型 是索引，一个索引类比mysql中的一张表，

index-type-mapping-document-field

库      表       表结构定义     行          一个字段的值

一个索引会被拆成多个shard   每个shard中放索引的一部分数据(有副本，备份)

 	会存在一个master node  维护索引元数据单位，

当主宕机之后 回将备份数据变成主数据

写只能用主数据写，  写可以从主从中任意一个读取

当宕机的机器修复，会识别是否有主数据，如何将自己修改为备份数据

## ES写入和查询的工作流程是什么样子的

ES随意选择一个进程写入一条数据 这个节点为 协调节点 ， 对数据进行hash 然后会找到其正确的shard所在（路由）， 会存储到一个shard中去，写入主数据，再备份到另一台机器中备份数据，协调节点会返回给客户端写成功

> 在shard内部如何写入：
>
> shard内部会有一个叫 内存buffer  ,数据会首先写入内存buffer中，同时写入日志文件中（translog），如果此时来查询，无法找到。
>
> 只有当内存buffer快满 或者每隔一段时间（1s）才会写入磁盘文件（segment file），相当于每秒钟会有一个新的segment file，包含了1秒中所有的数据
>
> 写入磁盘文件之前会进入OS cache,系统缓存   只要内存中的数据被执行如OS cache就可以被搜到
>
>  所以 ES 叫准实时        写入的数据 1秒后才能看见

问题，当translog文件大到一定程度时候，会触发commit，首先会触发refresh，将内存buffer中的数据写入到磁盘中去，然后会将commit point 写入磁盘文件中，里面标识者这个commit point对应的所有segment file 。会全部刷入到磁盘中去，刷完之后  会重新创建一个translog 文件

translog的作用：数据要么存在与buffer 还是 os cache 中，一旦机器死了，内存中的数据就会全部丢失，重启时，会重新读取  日志文件中的数据，写入到缓存中去

写入translog同时就建立好了 倒排索引

commit 完成

1. commit point 
2. os cache将数据刷入磁盘
3. 清空translog日志文件

可以手动 将数据输入到磁盘中 交flush操作

  translog文件也是在磁盘上面的,默认每个5秒回将translog写入到磁盘中，每隔30分钟将os中你的数据刷入到磁盘中

极端情况会有5秒的数据 存留在buffer,translog, os cache,segment file os cahce，中有五秒数据不在磁盘上，此时如果宕机会导致丢失，

如果希望不丢失，可以设置参数，

## 删除数据的原理

磁盘上有个叫 . del文件 ， 删除数据回将文件写入.del文件中，如将删除的数据写入到.del文件中去，客户端再去搜索的时候，在.del文件中标识了，就不会显示

merge:

> 当segment file 多到一定程度，就会触发merge操作，会将多个segment file 合并成一个大的，然后删除旧的文件
>
> 在merge期间，如果文件被标记为删除， merge时会删除文件



refresh ,flush,translog,merge

## 搜索  查询

查询 get 某一条数据，写入了某个document  会有唯一的doc id ，可以手动指定，可以随机生成，可以通过doc id来查询

全文检索：

将搜索请求发送到所有shard中去，查询所有的本地的shard，所有包含的关键字，返回到协调节点，然后再次进行筛选，筛选之后根据doc id 再去查询到所有的信息，最后返回给 客户端。

## 几十亿数据级的场景，如何提高效率

第一次搜索较慢，第二次之后会变快

不存在“银弹“ ，不可能通过某一个东西达成目标，大幅度提高性能，

file system cache,  也就是os cache，操作系统缓存

读取流程

客户端通过shard从磁盘文件中读，首先会从filesystem cache中查找，没有再去查找磁盘文件，在磁盘文件中查找到之后，再缓存到filesystem cache中，返回到客户端

es搜索引擎的查询性能其实是依赖于filesystem cache ，如果filesystem cache内存够大，可以存储所有的数据，速度会很快，

> 如果走磁盘搜索，一定是秒级以上，如果搜索是走filesystem cache，是纯内存的，那么一般来说基本上就是毫秒级的

实例 ：每台机器64G  filesystem 32G 32*3 96个G ，ES每台占32G

写入1T的数量，此时一台应该存储300G，所以只有30G的内容在filesystem cache中，磁盘上有270个G的数据。下次读取时，只有10%的情况不需要读磁盘，

总结：ES想要读写性能好，filesystem cache的内存必须至少达到总数据的一半

> 在ES中只存储最重要（需要用来检索的几个字段）的数据，保证所有数据都存在于，filesystem cache,速度极快，可以使用ES+Hbase的架构，对Hbase写入海量数据，不要做复杂的搜索。

从ES中根据name和age去搜索，拿到的结果可能就20个docid，然后根据doc id到hbase里去查询每个docid对应的完整数据，再去Hbase中查询



2.缓存预热 

将用户频繁访问的数据，写个后台任务，每隔一会搜索一下热数据，当用户查找的时候，会通过filesystem cache查找。

3.冷热分离

ES性能优化，数据拆分。

将热数据，冷数据分离，这样热数据被加载到filesystem cahce中之后，避免被冷数据加载覆盖

> 假日有6台机器，2个索引，一个放冷，一个放热，每个索引有3个shard，3台放热数据，3台放冷数据，
>
> 你大量的时候访问热数据的index,热数据可能就占总数据的10%，此时数据量很少，几乎全部都保留在filesystem cache中，就可以确保热数据的访问性能是很高的，
>
> 但是对于冷数据而言，是在别的index中的，更热数据index都在不相同的机器上，大家互相之间都没有什么影响，此时性能差点，但是访问的人特别少，所以基本没有什么影响

4.document 的设计

不要使用复杂的关联查询

关系到ES里的数据模型， 

5.分页的性能优化

 查询分页数据是，需要从每个shard中提取1000条数据到协调节点，如何根据排序将1000条数据，再次分页，拿到第100也的数据，所以分页越深，消耗的时间越多

> 解决方法：
>
> 1. 默认不允许深度分页，分页的性能很差
>
> 2. scroll 类似微博，不断下拉刷新数据，保留一个数据快照，在一定时间内，如果不断的向后翻页的时候。利用scroll不断通过游标获取下一页数据，这个性能是很高的，比ES实际翻页好很多
>
>     无论翻多少页，性能很好，
>
>     scroll 是只能一页页往后翻的，是不能跳页的。
>
>     所以很多网页 网站不能随意翻页 只能一页页往后翻

## 分布式搜索引擎如何部署

生成集群的部署架构是什么，每个索引的数据量大概有多少，每个索引大概有多少分片

## ES面试问题

kafka复制底层原理，leader选举的算法，增加partition以后的Rebalance算法，如果优化kafka的写入的吞吐

ES底层相关度的评分算法，deep paging,上千万数据的批处理，跨机房多集群的同步，搜索效果优化，等很多实际生产问题，

## 分布式缓存

项目里哪里用，为啥要用，不用行不行，用了之后有没有什么后果 

1. 高性能（读写快），高并发（能够承载的连接量远超普通数据库）
2. 后果：数据不一致，穿透，雪崩，击穿，缓存并发竞争



## 为什么redis单线程 还能有这么高的效率

1. redis 和 memcached 的区别

    拥有更多的数据结构，支持更多复杂的场景

    集群模式，redis原生支持主从模式

2. redis线程模型

    > redis 实现 文件时间处理器 ：单线程，采用IO多路复用的机制同时监听多个socket根据socket上的事件来选择对应的事件处理器来处理这个事件
    >
    > 通信流程：
    >
    > redis在启动初始化的时候，redis会将连接应答处理器更AE_READABLE事件关联起来，接着如果一个客户端更redis发起连接，此时会产生一个AE_READABLE事件

    客户端通过socket 与redis连接  服务端由server socket监听 连接。

    连接后产生， 一个AE_READABLE

    IO多路复用程序监听AE_READABLE事件，代表有一个新的客户端来连接redis了 ，

    将这个事件压到一个队列中

    文件事件分派器，事件处理器（连接应答处理器，命令请求处理器，命令回复处理器）

    连接应答处理器会创建出来一个 和客户端socket连接的socket ，然后将socket与AE_READABLE事件与命令请求处理器连接起来

    命令请求处理器，此时从socket中读出来key和value在自己内存中完成设置，将AE_WRITEABLE事件和命令回复处理器关联起来

    

    名回复处理器  对socket 输出本次操作的结果，socket会找到对应的客户端socket 然后返回结果，最后命令回复处理器会解除关联

3. 为什么单线程效率也这么高

    1 纯内存操作

    2 核心是非阻塞的IO多路复用机制：这个单线程拿到了各个socket 不负责处理，只是负责压入队列。

    3 单线程避免了 多线程上下文切换

## redis数据类型



## redis 过期策略  手写LRU算法

内存是有限的 ，所以存储不下会将不常用的数据干掉

1.设置过期时间

定期删除+惰性删除  可以保证过期的key一定会被干掉

![image-20191217110544310]($%7Bpic%7D/image-20191217110544310.png)



## 如何保证redis高并发，高可用  QPS上10W 上百万

单机的redis不能支持高并发  最高的QPS大概在上W，到几W不等 ，和业务的复杂程度有关

读写分离，对缓存 来说大部分请求都是读请求， 只有很少的是写请求

主负责写，，从节点负责读



## 异步复制 和 集群脑裂

如果任意一个slave 有超过10秒的数据没有被复制 主就会暂停接受写请求 

脑裂:如果slave超过10秒没有给ack信息，那么旧拒绝新的写请求信息，所以在脑裂的情况下最多就丢失10秒的数据

## redis高并发

主从架构 一主多从，一般来说，很多项目其实就够了，单主用来写入数据，多从用来查询数据，多个实例可以提供每秒10W的QPS，如果还需要容纳大量的数据，就使用多主多从。可以提供最高几十万的读写并发。

## redis 高可用

如果你做主从架构部署，其实加上哨兵就可以了，就可以实现任意一个实例宕机，主从自动切换

 

## redis 挂掉之后数据可以进行恢复

持久化就是为应对灾难性故障以及数据恢复，以及故障后尽快让redis变的可用



AOF 写入写入aof文件之前会先写入os cache 。每隔一秒将os cache中你的数据刷入到磁盘文件中



aof rewrite操作，当aof文件到一定程度的时候，就会发生重写，会根据当前的全部数据生成一个更小的aof文件



## rdb aof 的优缺点

rdb 

> 定时生成全量 文件， 适用于做冷备份。rdb可以保证redis的性能最高， 因为是每隔一段时间才生成一个快照进行备份，
>
> 根据RBD恢复 速度更快

aof

> 更好保证数据不丢失，最多每次丢失1秒的数据
>
> qps降低，，如果理论上不丢失 可以设置没一条指令都备份但是这样会找出效率大幅度降低
>
> aof日志文件rdb文件大的多，
>
> 每次重写是基于当时内存的数据进行指令的重新构件，健壮性会更好、
>
> 冷备份 恢复时花费的时间过长



rdb aof如何选择

两个同时使用 rdb 做冷备份，，aof做实时备份



## redis主从原理 集群





## 缓存雪崩 穿透

雪崩：缓存突然宕机，然后所有请求落在数据库上，数据库不能承受如此大的冲击，数据库之间崩溃，造成整个系统完全崩溃。

> 事前：先查本地的缓存，如果没有再查redis,查到了之后再将redis中的数据写入redis和本地缓存
>
> 事中：使用hystrix限流避免 mysql被打死，没有通过的会走降级，
>
> 好处 数据库绝对不会死  只要数据库不死，依然有部分用户可以正常使用，你的系统还是正常的
>
> 事后：redis 持久化

穿透：请求数据库和缓存中根本不存在，数据库会有大量的请求不存在的问题，导致穿透，以至于数据库崩溃

> 查询不到也将空值 放在缓存中
>
> 设置范围：不存在缓存范围中的值，直接不请求数据库

## 缓存和数据库读写不一致

1.初级   先修改数据库，再删除缓存 如果删除失败了，那么数据库中就是新数据，而缓存中为旧数据

> 先删除缓存，再更新数据库  即使修改数据库失败了，那么缓存中也没有数据，再次读数据库，添加到缓存中，数据依旧一样的

2.比较复杂：更新数据库，和读取缓存，并发发生，也还是会导致数据库和缓存双写不一致的情况

> 

3.上亿流量问题在高并发场景下，缓存会出现这个问题

只有对一个数据在并发的进行场景下，缓存会出现问题

4.读写异步串行化

数据库内存会有内存队列，会根据 商品ID 作为标识进行路由，相同的商品ID进行hash取值，再加上对内存队列的数量进行取模，每个商品都可以路由到某一个内存队列中，每一个内存队列都绑定一个线程



一般来说，如果系统不是强一致性的，最好不要做以上方案，因为只能串行化，串行到一个内存队列里去，一旦进行串行化，会导致系统的吞吐量大幅度降低。用比正常情况下多几倍的机器去支撑一个请求

## redis并发竞争问题，如何解决 了解Redis事务CAS吗

并发竞争问题

系统A部署在三台机器上，在某个时刻，多个系统实例都要去更新某个key

需要使用分布式锁:确保同一时间只有一个系统实例在操作，写之前判断时间戳是否符合常识

1.基于zk

## 生产环境redis集群如何部署的

5主 5 从

每台主挂一个从

5个节点对外提供读写  每个节点读写QPS可能达到5W/s   即最多25W   32G+8核 

但是分配给redis内存的尽量不要超过10G，超过10G可能会有问题

100条数据 1M        10W 1G数据  

## 分布式相关缓存回答技巧



## 分布式系统的连环炮























